{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebe2eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bsp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import re\n",
    "from datetime import datetime, timedelta,date\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\pcsea\\\\work1\\\\Self_study\\\\Company_news_PJ\\\\KOSPI200_NEWS')\n",
    "corplist200 = pd.read_csv('corplist200.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1d32910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>삼성전자</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SK하이닉스</td>\n",
       "      <td>000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NAVER</td>\n",
       "      <td>035420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG화학</td>\n",
       "      <td>051910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>현대차</td>\n",
       "      <td>005380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>일양약품</td>\n",
       "      <td>007570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>JW중외제약</td>\n",
       "      <td>001060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>SPC삼립</td>\n",
       "      <td>005610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>삼양사</td>\n",
       "      <td>145990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>빙그레</td>\n",
       "      <td>005180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company    code\n",
       "0      삼성전자  005930\n",
       "1    SK하이닉스  000660\n",
       "2     NAVER  035420\n",
       "3      LG화학  051910\n",
       "4       현대차  005380\n",
       "..      ...     ...\n",
       "147    일양약품  007570\n",
       "148  JW중외제약  001060\n",
       "149   SPC삼립  005610\n",
       "150     삼양사  145990\n",
       "151     빙그레  005180\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corplist2001 = []\n",
    "for i in range(len(corplist200)):\n",
    "    target = corplist200['code'][i]\n",
    "    corplist2001.append('{0:06d}'.format(target))\n",
    "corplist200['code'] = corplist2001\n",
    "corplist200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15589eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 스코어 저장\n",
    "scoredata = {}\n",
    "columns_sc = ['codeno', 'logistic_acc', 'randomFore_acc']\n",
    "scoredf = pd.DataFrame(scoredata, columns=columns_sc)\n",
    "\n",
    "# 단어저장\n",
    "clpndata = {}\n",
    "columns_clpn = ['codeno', 'positive_corr10', 'negative_corr10']\n",
    "clpndf = pd.DataFrame(clpndata, columns=columns_clpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5c75aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 뉴스데이터 전치리\n",
    "# 개별기업 뉴스 db에서 기사 가져오기\n",
    "# 기업별 뉴스 DB 모음으로 이행\n",
    "# os.chdir('C:\\\\Users\\\\pcsea\\\\work1\\\\Self_study\\\\Company_news_PJ\\\\newss')\n",
    "def getSub(dbname):\n",
    "#     dbname='yinfo_KCC.db'\n",
    "    with sqlite3.connect(dbname) as conn:\n",
    "        cursor=conn.cursor()\n",
    "        sql='select content from news '\n",
    "        res=cursor.execute(sql).fetchall()\n",
    "        result=[]\n",
    "        for r in res:\n",
    "            result.append(r[0])\n",
    "            \n",
    "    return result\n",
    "\n",
    "# 꼬마 불러오기\n",
    "from konlpy.tag import Kkma\n",
    "kkma=Kkma()\n",
    "\n",
    "# 주요 형태소만으로 이루어진 기사만들기\n",
    "def getPOS(rres,limlen=0):\n",
    "    p=kkma.pos(rres)\n",
    "    dictpos={}\n",
    "    words=[]\n",
    "    #표제어 추출\n",
    "    check=['NNG','NNP','NNB','NNM','VV','VA','VXV','VXA','VCP','VCN','XR']\n",
    "    for  w,pos in p:\n",
    "        if(pos in check):\n",
    "            if(len(w)>limlen): #불용어 처리 : 숫자,외국어, 특수문자와 광고문자, 길이가 적은 문자(1개 이하) 모두 완료.\n",
    "                words.append(w)\n",
    "                if (w in dictpos.keys()):\n",
    "                    dictpos[w]+=1\n",
    "                else:\n",
    "                    dictpos[w]=1\n",
    "    return (dictpos,words)  \n",
    "\n",
    "#하나의 주요한 형태소만으로 이루어진 기사내용(list)를 하나의 글로 만듬\n",
    "def getCorpus(doc):\n",
    "    getp=getPOS(doc,1)\n",
    "    sen=' '.join(getp[1])\n",
    "    return sen\n",
    "\n",
    "def getDB(sql='select nidx,ndate from nnews where nday is NULL'):\n",
    "    with sqlite3.connect(dbname) as conn:\n",
    "        cur=conn.cursor()\n",
    "        #sql='select * from stockp where skey>20200101 order by skey asc'\n",
    "        qry=cur.execute(sql)\n",
    "        desc=[row[0] for row in qry.description]\n",
    "        data=qry.fetchall()\n",
    "    return((desc,data))\n",
    "\n",
    "#### 3개 언론사가 kospi 기업별로 합쳐진 db를 넣으세요.\n",
    "def getDB2(sql='select nidx,ndate from nnews where nday is NULL'):\n",
    "    with sqlite3.connect(dbname2) as conn:\n",
    "        cur=conn.cursor()\n",
    "        #sql='select * from stockp where skey>20200101 order by skey asc' \n",
    "        qry=cur.execute(sql)\n",
    "        desc=[row[0] for row in qry.description]\n",
    "        data=qry.fetchall()\n",
    "    return((desc,data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fbe19d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------SK하이닉스000660--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5304888308003705\n",
      "0.8104533899676708\n",
      "0.2895928636152439\n",
      "0.29801885945399487\n",
      "0.27099678354992784\n",
      "0.4936063205294939\n",
      "0.45561474537946545\n",
      "0.8068961996520743\n",
      "0.5502766453710228\n",
      "0.8480797764246646\n",
      "0.8376912604999789\n",
      "0.7411007356361485\n",
      "0.5582668586663939\n",
      "0.3446346913995073\n",
      "0.7598947776069812\n",
      "0.3944145976001868\n",
      "0.7815420847290885\n",
      "0.25880878070705376\n",
      "0.8759882511948326\n",
      "0.40900030210984084\n",
      "0.33023629308943253\n",
      "0.7254660904368556\n",
      "0.8611771702075773\n",
      "0.6188578908038197\n",
      "0.41894021258982844\n",
      "1.0\n",
      "0.4701845033283118\n",
      "0.9410074793815796\n",
      "0.5703843765855127\n",
      "0.5061314077158361\n",
      "0.4473702713798826\n",
      "0.21297607724728648\n",
      "0.4072394592544727\n",
      "0.773462890352723\n",
      "0.8554339283978138\n",
      "0.324233285002108\n",
      "0.43716205259501884\n",
      "0.4022316089024661\n",
      "0.5120158723809353\n",
      "0.5935557680247997\n",
      "0.5130118635040601\n",
      "0.22617884324498036\n",
      "0.5457285053655045\n",
      "0.3541133662027086\n",
      "0.3922077575721074\n",
      "0.8850909325319567\n",
      "0.4260168921791697\n",
      "0.2915473523958973\n",
      "0.6405928669253705\n",
      "0.408404680554137\n",
      "0.46825540616075173\n",
      "0.8804971727488957\n",
      "0.577371700359053\n",
      "0.7716242554406391\n",
      "0.8217913133615367\n",
      "0.43636543242177056\n",
      "0.3581005430160832\n",
      "0.28581879122007026\n",
      "0.7787613678444893\n",
      "0.7619856882838323\n",
      "0.27701862355745016\n",
      "0.32156842319484047\n",
      "0.2987284611443016\n",
      "0.5819928237635166\n",
      "0.5255873950208643\n",
      "0.5347500122043731\n",
      "0.2953244942339828\n",
      "0.4848746369549601\n",
      "0.7005717995765148\n",
      "0.37993476599678455\n",
      "0.46565516547190433\n",
      "0.379065471732204\n",
      "0.511618554084274\n",
      "0.6895039529878259\n",
      "0.5417451958124418\n",
      "0.44696039066568816\n",
      "0.4622965637329396\n",
      "0.4082887254102663\n",
      "0.7027418316797899\n",
      "0.4201948584656925\n",
      "0.5455417406164935\n",
      "0.24204384004363833\n",
      "0.6348840006991936\n",
      "0.2512515980650971\n",
      "0.5872336100408638\n",
      "0.5702814002981619\n",
      "0.4202638990264061\n",
      "0.7891885701652488\n",
      "0.4251685220113786\n",
      "0.47013844398583626\n",
      "0.44187963133666397\n",
      "0.43762882407553677\n",
      "0.47923767793137795\n",
      "0.49032655172470785\n",
      "0.5068043859301282\n",
      "0.49522896869242033\n",
      "0.9893376576842806\n",
      "1.0\n",
      "0.6002416090126497\n",
      "0.6580525755477756\n",
      "0.4553377702580096\n",
      "0.8629326345883465\n",
      "0.41159530153345747\n",
      "0.42948656789258877\n",
      "0.6583326371470032\n",
      "0.2768836201993528\n",
      "0.31165835858667507\n",
      "0.6717034165624727\n",
      "0.4917333815037246\n",
      "0.3248095171707377\n",
      "0.2773125267045887\n",
      "0.7470985990847411\n",
      "0.4198360233939225\n",
      "0.3352816291193022\n",
      "0.33389989737094566\n",
      "0.3846909920847622\n",
      "0.5860115500000161\n",
      "0.4167976373482986\n",
      "0.311966013703729\n",
      "0.783378777512989\n",
      "0.23506965520556625\n",
      "0.24546658978146493\n",
      "0.28600663115555747\n",
      "0.27266624124562056\n",
      "0.43327369840283014\n",
      "0.3934134203677391\n",
      "0.6633515114177918\n",
      "0.3610173411258161\n",
      "0.4955428749047908\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.6457481020850975\n",
      "0.8830982673193131\n",
      "0.9141291872430222\n",
      "1.0\n",
      "0.9358462733089447\n",
      "0.5906975510453579\n",
      "0.9042428815672061\n",
      "0.6188242077315486\n",
      "0.4772190122171699\n",
      "0.5834214090734923\n",
      "0.6132828832746415\n",
      "0.6188797643233722\n",
      "0.4934178050366859\n",
      "0.7579665935277992\n",
      "0.9337148106409803\n",
      "0.4639013607215785\n",
      "0.3485123818285495\n",
      "0.32101467419443397\n",
      "0.25722047778678214\n",
      "0.5102976253156947\n",
      "0.2616042309999476\n",
      "0.4171301745792553\n",
      "0.421979138528997\n",
      "0.4382303689806035\n",
      "0.5729038655954094\n",
      "0.20379617424715787\n",
      "0.2461189028836263\n",
      "0.5657009700773177\n",
      "0.4492309048993294\n",
      "0.4704168749292664\n",
      "0.4852414466971848\n",
      "0.4880140523402709\n",
      "0.3438214777199342\n",
      "0.2268096050498408\n",
      "0.20935458024667444\n",
      "0.17932855950066698\n",
      "0.3809406130331908\n",
      "0.2392362973567358\n",
      "0.7444141887133621\n",
      "0.5884711340143836\n",
      "0.3885203986804409\n",
      "0.32554740148297506\n",
      "0.2612471607618573\n",
      "0.8380509263864715\n",
      "1.0\n",
      "0.5328253340301592\n",
      "0.8158564134431225\n",
      "0.9296466526208235\n",
      "0.771125942796038\n",
      "1.0\n",
      "1.0\n",
      "0.6295596912403574\n",
      "0.3685399300554394\n",
      "0.5000564031118763\n",
      "0.49680383096841124\n",
      "0.5501144573364448\n",
      "0.8608215420252558\n",
      "0.574806183368042\n",
      "0.7441995104184247\n",
      "0.8276874924216227\n",
      "0.8413062848927326\n",
      "0.7081401855429185\n",
      "0.7872020555264223\n",
      "0.48468431753560054\n",
      "0.19000909463407395\n",
      "0.3442045101317394\n",
      "0.2159207992205819\n",
      "0.42302057660010417\n",
      "0.35046759966969876\n",
      "0.8263862013743858\n",
      "0.4871871968160579\n",
      "0.45663668583514916\n",
      "0.7836721352730998\n",
      "0.438717290955992\n",
      "0.6912333671230186\n",
      "0.377249037585169\n",
      "0.489099594456101\n",
      "0.544273872824038\n",
      "0.3378593934072843\n",
      "0.5229377995099173\n",
      "0.5357179940837898\n",
      "0.3461407314181087\n",
      "0.35616835193756363\n",
      "0.5256307870783169\n",
      "0.2656783827278301\n",
      "0.28393813627053277\n",
      "0.39186559461876824\n",
      "0.5193611694350297\n",
      "0.5383391435099076\n",
      "0.388242700463488\n",
      "0.5200055113954776\n",
      "0.25341251891104655\n",
      "0.4035414325203576\n",
      "0.26913543716956\n",
      "0.5159039187337406\n",
      "0.25144063190807137\n",
      "0.5326573644637969\n",
      "0.28117492440346864\n",
      "0.3424914884812661\n",
      "0.7320538981405039\n",
      "0.4128206499065889\n",
      "0.2500541333567872\n",
      "0.3229806921677777\n",
      "0.8384821718735348\n",
      "0.5121909847925248\n",
      "0.2426286468210507\n",
      "0.2532567604212851\n",
      "0.3253954530186699\n",
      "0.4896294013654321\n",
      "0.5267370042832988\n",
      "0.2352752327298629\n",
      "0.2621563663824486\n",
      "0.6570337884081068\n",
      "0.33038487356884794\n",
      "0.3961031198305836\n",
      "0.33396678067689395\n",
      "0.3258713039859731\n",
      "0.4282187773956495\n",
      "0.25592123345779194\n",
      "0.5451414276021767\n",
      "0.5849903272238316\n",
      "0.4270409881237934\n",
      "0.5304731895761506\n",
      "0.34460518272797397\n",
      "0.7265395400945365\n",
      "0.336192499514244\n",
      "0.40755545714233177\n",
      "0.5191670222040641\n",
      "0.578563119836053\n",
      "0.47129698015407206\n",
      "0.1892670391232441\n",
      "0.48190514138193086\n",
      "0.7489334061192298\n",
      "0.49084057526375524\n",
      "0.44453721421882864\n",
      "0.3598676943615285\n",
      "0.49498866480338644\n",
      "0.38330585918016397\n",
      "0.37809774509154165\n",
      "0.45969235366793576\n",
      "0.4568313327697918\n",
      "0.28551969574410996\n",
      "0.746108789223675\n",
      "0.3943662510883811\n",
      "0.34940187586830934\n",
      "0.3873570915890843\n",
      "0.3001256505498749\n",
      "0.39588455220319724\n",
      "0.2692384340156397\n",
      "0.32468040637028583\n",
      "0.4285941563426799\n",
      "0.882865325404082\n",
      "0.888123539930249\n",
      "0.6636258422123856\n",
      "0.4198785173290872\n",
      "0.3927774487925967\n",
      "0.324528497364249\n",
      "0.2183415971364756\n",
      "0.5674387019179924\n",
      "0.45480159596369046\n",
      "0.7496988819807264\n",
      "0.6500728927808914\n",
      "0.5238611673541992\n",
      "0.6228773893683118\n",
      "0.3253810763904758\n",
      "0.23257344683905884\n",
      "0.36717100521815677\n",
      "0.29045893910215714\n",
      "0.283035111949691\n",
      "0.6512222861745858\n",
      "0.4164166704762415\n",
      "0.43632676141978954\n",
      "0.4512650000887734\n",
      "0.7283958904974591\n",
      "0.47853407420182126\n",
      "0.4472202863741712\n",
      "0.9084591983142408\n",
      "0.5566218519028223\n",
      "0.3229780490179671\n",
      "0.5547229242695318\n",
      "0.20094864297729678\n",
      "0.1945867473914271\n",
      "0.85487647046006\n",
      "0.21587805136091615\n",
      "0.4323871025095981\n",
      "0.45491316602315635\n",
      "0.3590928411799016\n",
      "0.5676242325422256\n",
      "0.4279812965750011\n",
      "0.42942716007587767\n",
      "0.45826382023966744\n",
      "0.497329390909037\n",
      "0.5306740157691177\n",
      "0.6057904580461484\n",
      "0.39877595917504466\n",
      "0.5902912844548351\n",
      "1.0\n",
      "0.2604308904334033\n",
      "0.8562501049456875\n",
      "0.12783378711487056\n",
      "0.3222370521906991\n",
      "0.12566876546851852\n",
      "0.5667906144657224\n",
      "0.8488666819416061\n",
      "0.12495835976473178\n",
      "0.257790724857433\n",
      "0.4829834774545005\n",
      "0.2873187792113931\n",
      "0.2790742499110891\n",
      "0.5688066976982046\n",
      "0.6667341294560839\n",
      "0.5298624534655485\n",
      "0.2842542017229084\n",
      "0.3323603750297217\n",
      "0.3147018847641957\n",
      "0.317051775856903\n",
      "0.28959459764316003\n",
      "0.39039615923959237\n",
      "0.33319730468769937\n",
      "0.2824631236226929\n",
      "0.3844588264160409\n",
      "0.37988788965758696\n",
      "0.37988788965758696\n",
      "0.3883954410999571\n",
      "0.27281265258091164\n",
      "0.46800762795066064\n",
      "0.25436385516476395\n",
      "0.8458797644605635\n",
      "0.2684994800056887\n",
      "0.25367106754018415\n",
      "0.2836987378184674\n",
      "0.3106359604356828\n",
      "0.2839042776472539\n",
      "0.3888611279608807\n",
      "0.29278947155679863\n",
      "0.33232031374783744\n",
      "0.25705805011675015\n",
      "0.2685470206414604\n",
      "0.37669685732703867\n",
      "0.38801045105035276\n",
      "0.3136483741022049\n",
      "0.27030854881005456\n",
      "0.332674917772461\n",
      "0.39958846899250083\n",
      "0.3074155163211968\n",
      "0.33472688353011343\n",
      "0.35941387107801015\n",
      "0.3260973011852962\n",
      "0.36760273469998384\n",
      "0.26344297715888637\n",
      "0.30163648446012103\n",
      "0.25918309667788253\n",
      "0.32566039458669754\n",
      "0.1218147564862602\n",
      "0.3278985386424042\n",
      "0.3078053069250428\n",
      "0.2984937605178983\n",
      "0.2870506878060977\n",
      "0.4363564145564626\n",
      "0.8169240219173348\n",
      "0.49567596884505266\n",
      "0.6525197494782223\n",
      "0.252830227630989\n",
      "0.5529296005957252\n",
      "0.4684226479719704\n",
      "0.42719538407649343\n",
      "0.26756849129278054\n",
      "0.24329318704919956\n",
      "0.6519914129957195\n",
      "0.2687623336991307\n",
      "0.5177562264985565\n",
      "0.6513274173702138\n",
      "0.3056736000086722\n",
      "0.35855969101999036\n",
      "0.4095226142254037\n",
      "0.29284088300838645\n",
      "0.9105389297744048\n",
      "0.39619024582358875\n",
      "0.7392360483567028\n",
      "0.18441311276693045\n",
      "0.4304777474532979\n",
      "0.21360490528087275\n",
      "0.23294200171505242\n",
      "0.5931747832265256\n",
      "0.7275103543213511\n",
      "1.0\n",
      "0.43828787239561284\n",
      "0.24057719859287574\n",
      "0.30716921483067283\n",
      "0.6747400610978193\n",
      "0.32788168790838784\n",
      "0.34514877412467415\n",
      "0.6057667242640581\n",
      "0.32724534681426254\n",
      "0.28809000365517706\n",
      "0.7658330512162431\n",
      "0.32679565573196817\n",
      "0.17833236713299772\n",
      "0.30372954181231154\n",
      "0.1941359666809817\n",
      "0.20444742862580234\n",
      "0.30467772452596786\n",
      "0.6235107934873566\n",
      "0.3345414290729625\n",
      "0.2823194917625044\n",
      "0.4773309028651198\n",
      "0.3091727526739047\n",
      "0.36978283452747734\n",
      "0.28974496368284014\n",
      "0.3097743503520224\n",
      "0.29720316868015806\n",
      "0.3204101312020532\n",
      "0.5325358022475329\n",
      "0.6087041703778161\n",
      "0.6144409975187298\n",
      "0.5178895954084827\n",
      "0.6144409975187298\n",
      "0.5406717593462276\n",
      "0.2913395863383659\n",
      "0.36761880950886516\n",
      "0.7970354033796865\n",
      "0.3307683017138818\n",
      "0.27566114775640166\n",
      "0.8110703672380498\n",
      "1.0\n",
      "0.35266806008927154\n",
      "0.5800294402436931\n",
      "0.6357736359727375\n",
      "0.2964222335184852\n",
      "0.5487929832106514\n",
      "0.2652507581406918\n",
      "0.21251775351856256\n",
      "0.29566309177311034\n",
      "0.19908917528399203\n",
      "0.23918035844647972\n",
      "0.2727797866454877\n",
      "0.45143563826375455\n",
      "0.42501940966655527\n",
      "0.394977756055497\n",
      "0.37701253433237597\n",
      "0.5981575077268372\n",
      "0.5386970121538849\n",
      "0.33864718436374736\n",
      "0.42916016447196376\n",
      "0.32913381463691777\n",
      "0.20994403279592408\n",
      "0.4740850918240024\n",
      "0.6098891183189468\n",
      "0.4357120175690349\n",
      "0.6672669286130337\n",
      "0.5380870407442853\n",
      "0.340284090320241\n",
      "0.8737623204338436\n",
      "0.2595956613033114\n",
      "0.4981371358329205\n",
      "0.3938962784165811\n",
      "0.8169781359316142\n",
      "0.5531868671111141\n",
      "0.46048284335814943\n",
      "0.3955795051722557\n",
      "0.7398610699427264\n",
      "0.5612315912195613\n",
      "0.6972303814078864\n",
      "0.40404944689906697\n",
      "0.3505088289362996\n",
      "0.7957622444424277\n",
      "0.4444431609631525\n",
      "0.5707286104222195\n",
      "0.8195184634235478\n",
      "0.4413090868111508\n",
      "0.49338194032196775\n",
      "0.37103778681687394\n",
      "0.2864416932472815\n",
      "0.19219645858122503\n",
      "0.3289418055455071\n",
      "0.5743732198379635\n",
      "0.45221237635538347\n",
      "0.4211717270293864\n",
      "0.5122745743949796\n",
      "0.3857176875994828\n",
      "0.3501596318896321\n",
      "0.3539844382580015\n",
      "0.16209275841287635\n",
      "0.23714924920734268\n",
      "0.38081112704704295\n",
      "0.38588999877395475\n",
      "0.4280013148815567\n",
      "0.4055427445355102\n",
      "0.4946274837087294\n",
      "0.3290674927885378\n",
      "0.23294149024019392\n",
      "0.33772048919977826\n",
      "0.5700933428755824\n",
      "0.3656844194339709\n",
      "0.3954850236544146\n",
      "0.5499323155562276\n",
      "0.889287809306828\n",
      "0.3372745083950442\n",
      "0.5275549155576562\n",
      "0.4211394557180587\n",
      "0.2930453744458316\n",
      "0.2886273289228971\n",
      "0.8255502802740297\n",
      "0.39493734655951307\n",
      "0.8162741308767956\n",
      "0.4411962472774482\n",
      "0.4435338714636282\n",
      "0.8855717774372508\n",
      "0.6996297221532859\n",
      "0.35756603666274506\n",
      "0.6354991275663325\n",
      "0.45063059447889314\n",
      "0.5489324230556043\n",
      "0.254977356078915\n",
      "0.457915643466216\n",
      "0.5436845341200669\n",
      "0.41506669042272704\n",
      "0.5868204815303361\n",
      "0.9141829134059717\n",
      "0.6102863123057614\n",
      "0.47345690219336645\n",
      "0.3856531654335888\n",
      "0.5060909788601442\n",
      "0.3764191354551396\n",
      "0.34970917056924894\n",
      "0.49336561475510793\n",
      "0.8086382217978655\n",
      "0.5512751146996643\n",
      "0.5082901577613986\n",
      "0.0\n",
      "0.45150896391400297\n",
      "0.5058298740503407\n",
      "0.5125208310445694\n",
      "0.3490574947503268\n",
      "0.5931062505949086\n",
      "0.5351029978348435\n",
      "0.42593537384127994\n",
      "0.5917641449643188\n",
      "0.6200752464361777\n",
      "0.9200288694651567\n",
      "0.4037391108778239\n",
      "0.5074094396197685\n",
      "0.2598093143429439\n",
      "0.35692889559164837\n",
      "0.28568626146259435\n",
      "0.572831557935099\n",
      "0.7385968809867492\n",
      "0.49683793882052285\n",
      "0.2993309246338\n",
      "0.5360097145954975\n",
      "0.54272835613131\n",
      "0.3479805756529992\n",
      "0.4624286221740641\n",
      "0.33864902539502645\n",
      "0.7169594843700612\n",
      "0.5633225950788083\n",
      "0.4172952657786238\n",
      "0.5552512328715373\n",
      "0.6025808491609483\n",
      "0.5174792919392837\n",
      "0.514116532470293\n",
      "0.36916344163822135\n",
      "0.5491553507239427\n",
      "0.9315162021180685\n",
      "0.6733082131129916\n",
      "0.5598015591156222\n",
      "0.5117272081568816\n",
      "0.4626686791166026\n",
      "0.3409459839475211\n",
      "0.2169270687544551\n",
      "0.5004961812623809\n",
      "0.5024416174846281\n",
      "0.6583453257111895\n",
      "0.4989005031249983\n",
      "0.34997889949280747\n",
      "0.22133638161906785\n",
      "0.5065487874445816\n",
      "0.5354420708335493\n",
      "0.6043372432493912\n",
      "0.5637814359339918\n",
      "0.7542762410978551\n",
      "0.33517759586170653\n",
      "0.6154191089777205\n",
      "0.34277536261891983\n",
      "0.8659909907216741\n",
      "0.37646932651293474\n",
      "0.7870529101322492\n",
      "0.31559780428762235\n",
      "0.1977297411304665\n",
      "0.8437590533522452\n",
      "0.8661021203141274\n",
      "0.8901577101268522\n",
      "0.8839683904277105\n",
      "0.3194805014148849\n",
      "0.27644777507946444\n",
      "0.3803789457199677\n",
      "0.4216061913560359\n",
      "0.4223264608492293\n",
      "confusion_matrix : \n",
      " [[168 158]\n",
      " [127 178]]\n",
      " \n",
      "accuracy_score :  0.5483359746434231\n",
      "          sdate   pre_por  polarity\n",
      "0    2020-05-08  0.500000       1.0\n",
      "1    2020-05-12  1.000000       1.0\n",
      "2    2020-05-13  0.500000       0.0\n",
      "3    2020-05-14  0.500000       0.0\n",
      "4    2020-05-18  0.500000       0.0\n",
      "..          ...       ...       ...\n",
      "133  2020-12-22  0.333333       0.0\n",
      "134  2020-12-23  1.000000       1.0\n",
      "135  2020-12-24  0.333333       1.0\n",
      "136  2020-12-28  1.000000       0.0\n",
      "137  2020-12-30  0.500000       1.0\n",
      "\n",
      "[138 rows x 3 columns]\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 764, in _logistic_regression_path\n",
      "    extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 243, in _check_optimize_result\n",
      "    ).format(solver, result.status, result.message.decode(\"latin1\"))\n",
      "AttributeError: 'str' object has no attribute 'decode'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 764, in _logistic_regression_path\n",
      "    extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 243, in _check_optimize_result\n",
      "    ).format(solver, result.status, result.message.decode(\"latin1\"))\n",
      "AttributeError: 'str' object has no attribute 'decode'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 764, in _logistic_regression_path\n",
      "    extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 243, in _check_optimize_result\n",
      "    ).format(solver, result.status, result.message.decode(\"latin1\"))\n",
      "AttributeError: 'str' object has no attribute 'decode'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 764, in _logistic_regression_path\n",
      "    extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 243, in _check_optimize_result\n",
      "    ).format(solver, result.status, result.message.decode(\"latin1\"))\n",
      "AttributeError: 'str' object has no attribute 'decode'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 764, in _logistic_regression_path\n",
      "    extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 243, in _check_optimize_result\n",
      "    ).format(solver, result.status, result.message.decode(\"latin1\"))\n",
      "AttributeError: 'str' object has no attribute 'decode'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 764, in _logistic_regression_path\n",
      "    extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 243, in _check_optimize_result\n",
      "    ).format(solver, result.status, result.message.decode(\"latin1\"))\n",
      "AttributeError: 'str' object has no attribute 'decode'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 764, in _logistic_regression_path\n",
      "    extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 243, in _check_optimize_result\n",
      "    ).format(solver, result.status, result.message.decode(\"latin1\"))\n",
      "AttributeError: 'str' object has no attribute 'decode'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 764, in _logistic_regression_path\n",
      "    extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 243, in _check_optimize_result\n",
      "    ).format(solver, result.status, result.message.decode(\"latin1\"))\n",
      "AttributeError: 'str' object has no attribute 'decode'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 764, in _logistic_regression_path\n",
      "    extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 243, in _check_optimize_result\n",
      "    ).format(solver, result.status, result.message.decode(\"latin1\"))\n",
      "AttributeError: 'str' object has no attribute 'decode'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 764, in _logistic_regression_path\n",
      "    extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "  File \"C:\\Users\\pcsea\\Anaconda3\\envs\\study\\lib\\site-packages\\sklearn\\utils\\optimize.py\", line 243, in _check_optimize_result\n",
      "    ).format(solver, result.status, result.message.decode(\"latin1\"))\n",
      "AttributeError: 'str' object has no attribute 'decode'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   48.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1} 0.5639\n",
      "logistict acc: 0.5483359746434231\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   13.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 7} 0.5405\n",
      "RamdomForest acc: 0.48335974643423135\n"
     ]
    }
   ],
   "source": [
    "for i in range(50,51):\n",
    "    codeno = str(corplist200['code'][i])\n",
    "    # 뉴스파일 이름\n",
    "    dbname = 'news_' + codeno +'.db'\n",
    "    print(\"------------------------\"+ corplist200['company'][i] + corplist200['code'][i]+'--------------------------')\n",
    "    \n",
    "    # 본격코드\n",
    "    os.chdir('C:\\\\Users\\\\pcsea\\\\work1\\\\Self_study\\\\Company_news_PJ\\\\newss')\n",
    "    docs = getSub(dbname)\n",
    "    corpus=[]\n",
    "    for doc in docs:\n",
    "        getp=getCorpus(doc)\n",
    "        corpus.append(getp)\n",
    "\n",
    "    sql= \"select * from news\"\n",
    "    gdata=getDB(sql)\n",
    "    df=pd.DataFrame(data=gdata[1],columns=gdata[0])\n",
    "    df['content'] = corpus\n",
    "    gdf = df[['title', 'date', 'content']]\n",
    "\n",
    "    # 날짜 형식 전처리\n",
    "    for i in range(len(gdf)):\n",
    "        gdf['date'][i] = gdf['date'][i].strip()\n",
    "        gdf['date'][i] = gdf['date'][i][:10].replace('.','-')\n",
    "\n",
    "    ### 주식데이터 전처리\n",
    "    # 기업별 주가 모음 DB로 연결\n",
    "    os.chdir('C:\\\\Users\\\\pcsea\\\\work1\\\\Self_study\\\\Company_news_PJ\\\\total')\n",
    "    # 주식파일 이름\n",
    "    dbname2 = codeno + '.db'\n",
    "    \n",
    "    sql= \"select sdate,sopen,shigh,slow,sclose,svol from stockp \"\n",
    "    mdata=getDB2(sql)\n",
    "    df=pd.DataFrame(data=mdata[1],columns=mdata[0])\n",
    "\n",
    "    # df 정렬 순서 바꾸기\n",
    "    df = df[::-1]\n",
    "    df['ydclose']=df['sclose'].shift(+1)\n",
    "    df['polarity']=df['sclose']-df['ydclose']\n",
    "    for i in range(len(df)):\n",
    "        if df['polarity'][i] > 0:\n",
    "            df['polarity'][i] = 1\n",
    "        else:\n",
    "            df['polarity'][i] = 0\n",
    "            \n",
    "    ### 텍스트 처리\n",
    "\n",
    "    gdf.columns = ['title', 'sdate', 'content']\n",
    "\n",
    "    # 개별 뉴스에 극성을 붙이는 것이 목적 -> 뉴스기준으로 merge\n",
    "    a = pd.merge(gdf, df, left_on='sdate', right_on='sdate', how='left')\n",
    "    a = a.dropna(axis=0)\n",
    "    b = a[['sdate','content','polarity']]\n",
    "    b = b[::-1]\n",
    "    b = b.reset_index(drop=True)\n",
    "\n",
    "    # 다른 언론사별로 데이터가 누적되어있어서 날짜순 정렬로 바꿈\n",
    "    bb = b.sort_values(by=['sdate'], axis=0).reset_index(drop=True)\n",
    "\n",
    "    # train, test 를 x(nl),y(polarity) 고려 나눔 < train : 0.8기준 >\n",
    "    \n",
    "    x_data = bb['content']\n",
    "    y_data = bb['polarity']\n",
    "    train_num= int(len(y_data)*0.7)\n",
    "#     train_num= 550\n",
    "    xtr = x_data[:train_num]\n",
    "    xte = x_data[train_num:]\n",
    "    ytr = y_data[:train_num]\n",
    "    yte = y_data[train_num:]\n",
    "    tr = bb[:train_num]\n",
    "    te = bb[train_num:]\n",
    "#     tr = bb[:2202]\n",
    "#     te = bb[2202:]\n",
    "#     xtr = tr['content']\n",
    "#     ytr = tr['polarity']\n",
    "#     xte = te['content']\n",
    "#     yte = te['polarity']\n",
    "\n",
    "\n",
    "    ### tfidf 변환\n",
    "    vect=TfidfVectorizer(min_df=2)\n",
    "    vect.fit(xtr)\n",
    "    tdm = vect.transform(xtr).toarray()\n",
    "    cols=vect.get_feature_names()\n",
    "    tdmdf=pd.DataFrame(data=tdm, columns=cols)\n",
    "    \n",
    "    ### 코사인 유사도\n",
    "    test1 = vect.transform(xte).toarray()\n",
    "    testdf=pd.DataFrame(data=test1, columns=cols) \n",
    "    # train과 test의 유사도 _ 결국 이부분이 예측\n",
    "    from sklearn.metrics.pairwise import cosine_similarity # 코사인 유사도 \n",
    "    similarity = cosine_similarity(testdf,tdmdf)\n",
    "\n",
    "    # 목적 test기사 250개의 극성 구하기\n",
    "    sim = []\n",
    "    por = []\n",
    "    tidx = []\n",
    "    for i in range(len(similarity)):\n",
    "        toppidx = np.argsort(similarity[i])[-1] # 가장 높은 1개로 함. #### 변경가능\n",
    "#         print(similarity[i][toppidx])\n",
    "        tidx.append(toppidx)\n",
    "        sim.append(similarity[i][toppidx])\n",
    "        por.append(ytr[toppidx])\n",
    "\n",
    "    simdf = pd.DataFrame (sim,columns=['sim'])\n",
    "    tidxdf = pd.DataFrame (tidx,columns=['tidx'])\n",
    "    pordf = pd.DataFrame (por,columns=['por'])\n",
    "    cos_f = pd.concat([pordf, simdf, tidxdf], axis=1)\n",
    "    real = yte.reset_index(drop=True)\n",
    "    cos_p = cos_f['por']\n",
    "\n",
    "    print('confusion_matrix : \\n', confusion_matrix(real, cos_p))\n",
    "    print(' ')\n",
    "    print('accuracy_score : ',accuracy_score(real, cos_p))\n",
    "    tee = te.copy().reset_index()\n",
    "    tee['pre_por'] = cos_f['por']\n",
    "\n",
    "    # tee.groupby\n",
    "    tee_f = tee[['sdate','pre_por','polarity']].groupby(tee['sdate']).mean()\n",
    "    os.chdir('C:\\\\Users\\\\pcsea\\\\work1\\\\Self_study\\\\Company_news_PJ\\\\KOSPI200_NEWS\\\\nlp_cos')\n",
    "    ### 여기는 종목별로 csv만들어야\n",
    "    #1 종목별 날짜의 '코사인 유사도 활용 예측극성'과 '실제 극성' \n",
    "    t1 = tee_f.reset_index(drop=False)\n",
    "    print(t1)\n",
    "    t1.to_csv(codeno +'_cos.csv', encoding='cp949', index=False)\n",
    "    \n",
    "\n",
    "\n",
    "    ### tfidf기반 nlp 머신러닝으로 주가 예측\n",
    "\n",
    "    #1. 로지스틱 회귀\n",
    "    lgclf = LogisticRegression(random_state=0)\n",
    "    params = { \"C\": [0.1,1,10,100]}\n",
    "    grid_cv = GridSearchCV(lgclf, param_grid=params, cv=5, scoring='accuracy', verbose=1 )\n",
    "    grid_cv.fit(tdm ,ytr)\n",
    "    print(grid_cv.best_params_, round(grid_cv.best_score_, 4))\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    test = vect.transform(xte)\n",
    "    best_estimator = grid_cv.best_estimator_\n",
    "    preds = best_estimator.predict(test)\n",
    "    lr_acscore = accuracy_score(preds,yte)\n",
    "    print('logistict acc:', accuracy_score(preds,yte))\n",
    "\n",
    "    #2. \n",
    "    # RandomForestClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rp = RandomForestClassifier()\n",
    "    params = { \"n_estimators\": [10,1,2,3,4,5,6,7,8,9]}\n",
    "    grid_cv = GridSearchCV(rp, param_grid=params, cv=3, scoring='accuracy', verbose=1 )\n",
    "    rpr = grid_cv.fit(tdm ,ytr)\n",
    "    print(grid_cv.best_params_, round(grid_cv.best_score_, 4))\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    test = vect.transform(xte)\n",
    "    best_estimator = grid_cv.best_estimator_\n",
    "    preds = best_estimator.predict(test)\n",
    "    rf_acscore = accuracy_score(preds,yte)\n",
    "    print('RamdomForest acc:', accuracy_score(preds,yte))\n",
    "\n",
    "    ### 단어의 정확도 파악\n",
    "    new_data = {\n",
    "        'codeno': codeno,\n",
    "        'logistic_acc': lr_acscore,\n",
    "        'randomFore_acc': rf_acscore\n",
    "    }\n",
    "    scoredf = scoredf.append(new_data, ignore_index=True)\n",
    "    scoredf\n",
    "    \n",
    "    # # 주식설명 2                  ############ 요부분 오래걸림\n",
    "    dp = bb[['sdate','polarity']][:train_num]\n",
    "    tidfnew = pd.concat([dp, tdmdf],axis =1,ignore_index=True)\n",
    "    tidfnew.columns = ['sdate','polarity'] + cols\n",
    "\n",
    "    df = pd.DataFrame(tidfnew)\n",
    "    # df.columns = ['sdate','polarity'] + cols\n",
    "    corr = df.corr(method = 'pearson')\n",
    "    print('양의 상관관계 :', corr['polarity'].sort_values()[-11:-1])\n",
    "    positive_corr10 = corr['polarity'].sort_values()[-11:-1]\n",
    "    print('음의 상관관계 :', corr['polarity'].sort_values()[:10])\n",
    "    negative_corr10 = corr['polarity'].sort_values()[:10]\n",
    "\n",
    "    pdf = positive_corr10.reset_index(drop=False)\n",
    "    ndf = negative_corr10.reset_index(drop=False)\n",
    "\n",
    "\n",
    "    pdf.to_csv(codeno +'_pcorr_df.csv', encoding='cp949', index=False)\n",
    "    pdf.to_csv(codeno +'_ncorr_df.csv', encoding='cp949', index=False)\n",
    "    \n",
    "scoredf.to_csv(codeno +'scoredf.csv', encoding='cp949', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
